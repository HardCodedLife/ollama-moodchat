# ğŸ—ï¸ MoodChat Architecture

## System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER BROWSER                            â”‚
â”‚                     http://localhost:5173                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚  HTTP + WebSocket
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REACT FRONTEND (Vite)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   App.tsx   â”‚  â”‚  themes.ts  â”‚  â”‚   api.ts (REST +     â”‚   â”‚
â”‚  â”‚  (Main App) â”‚  â”‚ (12 Themes) â”‚  â”‚   WebSocket Client)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    COMPONENTS                          â”‚   â”‚
â”‚  â”‚  â€¢ ConversationList (Sidebar)                         â”‚   â”‚
â”‚  â”‚  â€¢ ChatInterface (Main Chat)                          â”‚   â”‚
â”‚  â”‚  â€¢ NewConversationModal (Create Dialog)               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚  REST API (port 8000)
                         â”‚  WebSocket (/ws/{id})
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FASTAPI BACKEND (Python)                      â”‚
â”‚                     server_new.py                               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  REST ENDPOINTS                                          â”‚  â”‚
â”‚  â”‚  â€¢ GET  /api/conversations                              â”‚  â”‚
â”‚  â”‚  â€¢ POST /api/conversations                              â”‚  â”‚
â”‚  â”‚  â€¢ GET  /api/conversations/{id}                         â”‚  â”‚
â”‚  â”‚  â€¢ PUT  /api/conversations/{id}                         â”‚  â”‚
â”‚  â”‚  â€¢ DELETE /api/conversations/{id}                       â”‚  â”‚
â”‚  â”‚  â€¢ POST /api/conversations/{id}/files                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  WEBSOCKET ENDPOINT                                      â”‚  â”‚
â”‚  â”‚  â€¢ /ws/{conversation_id}                                â”‚  â”‚
â”‚  â”‚    - Receive user messages                              â”‚  â”‚
â”‚  â”‚    - Stream AI responses                                â”‚  â”‚
â”‚  â”‚    - Detect and send theme updates                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  IN-MEMORY STORAGE                                       â”‚  â”‚
â”‚  â”‚  â€¢ conversations_db: {id: conversation_data}            â”‚  â”‚
â”‚  â”‚  â€¢ active_sessions: {ws_id: session_data}               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  THEME DETECTION ENGINE                                  â”‚  â”‚
â”‚  â”‚  â€¢ Analyzes last 6 messages                             â”‚  â”‚
â”‚  â”‚  â€¢ Calls Ollama with detection prompt                   â”‚  â”‚
â”‚  â”‚  â€¢ Returns theme: romance/adventure/calm/etc.           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚  HTTP POST (localhost:11434)
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OLLAMA SERVER                              â”‚
â”‚                   http://localhost:11434                        â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  LLM MODEL (e.g., llama3.2)                             â”‚  â”‚
â”‚  â”‚  â€¢ Loaded in memory                                      â”‚  â”‚
â”‚  â”‚  â€¢ Processes chat messages                               â”‚  â”‚
â”‚  â”‚  â€¢ Generates streaming responses                         â”‚  â”‚
â”‚  â”‚  â€¢ Analyzes sentiment for theme detection                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Message Flow

### Creating a Conversation

```
User â†’ Frontend Modal â†’ POST /api/conversations
                        â†“
                   Backend creates conversation
                        â†“
                   Returns {conversation_id, conversation}
                        â†“
                   Frontend stores & displays
```

### Sending a Message

```
User types â†’ Frontend â†’ WebSocket.send({message: "..."})
                             â†“
                        Backend receives
                             â†“
                        Prepares context (custom + history)
                             â†“
                        POST to Ollama /api/chat (streaming)
                             â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â–¼                   â–¼
            WebSocket sends        Backend saves
            chunks to frontend     complete response
                   â–¼
            Frontend displays
            character-by-character
                   â–¼
            After 6+ messages
            Backend runs theme detection
                   â–¼
            WebSocket sends new theme
                   â–¼
            Frontend transitions background
```

### Theme Detection Flow

```
Conversation reaches 6+ messages
            â†“
Backend extracts last 6 messages
            â†“
Formats as text: "user: ...\nassistant: ...\n..."
            â†“
Sends to Ollama with THEME_DETECTOR_PROMPT
            â†“
Ollama analyzes emotional tone
            â†“
Returns single word: "romance" / "adventure" / etc.
            â†“
Backend validates against theme list
            â†“
Updates conversation.current_theme
            â†“
Sends theme to frontend via WebSocket
            â†“
Frontend applies new theme (0.8s transition)
```

## Component Hierarchy

```
App.tsx
â”‚
â”œâ”€â”€ ConversationList
â”‚   â”œâ”€â”€ Header
â”‚   â”‚   â”œâ”€â”€ Title
â”‚   â”‚   â””â”€â”€ New Chat Button
â”‚   â”‚
â”‚   â””â”€â”€ Conversation Items (map)
â”‚       â”œâ”€â”€ Title
â”‚       â”œâ”€â”€ Metadata (messages, date)
â”‚       â””â”€â”€ Delete Button
â”‚
â”œâ”€â”€ Main Content Area
â”‚   â”‚
â”‚   â”œâ”€â”€ ChatInterface (if conversation selected)
â”‚   â”‚   â”œâ”€â”€ Chat Header
â”‚   â”‚   â”‚   â”œâ”€â”€ Conversation Title
â”‚   â”‚   â”‚   â””â”€â”€ Theme Indicator
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Messages Area (scrollable)
â”‚   â”‚   â”‚   â”œâ”€â”€ User Messages (map)
â”‚   â”‚   â”‚   â”œâ”€â”€ Assistant Messages (map)
â”‚   â”‚   â”‚   â””â”€â”€ Typing Indicator (if active)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Input Area
â”‚   â”‚       â”œâ”€â”€ Textarea
â”‚   â”‚       â””â”€â”€ Send Button
â”‚   â”‚
â”‚   â””â”€â”€ Welcome Screen (if no conversation)
â”‚       â”œâ”€â”€ Title
â”‚       â”œâ”€â”€ Description
â”‚       â””â”€â”€ Start Button
â”‚
â””â”€â”€ NewConversationModal (conditional)
    â”œâ”€â”€ Header (Title + Close)
    â”œâ”€â”€ Body
    â”‚   â”œâ”€â”€ Title Input
    â”‚   â”œâ”€â”€ Context Textarea
    â”‚   â”œâ”€â”€ File Upload
    â”‚   â””â”€â”€ Example Contexts
    â””â”€â”€ Footer
        â”œâ”€â”€ Cancel Button
        â””â”€â”€ Create Button
```

## State Management

### Frontend State (React)

```typescript
// App.tsx
const [conversations, setConversations] = useState<ConversationSummary[]>([])
const [currentConversation, setCurrentConversation] = useState<Conversation | null>(null)
const [showNewConversationModal, setShowNewConversationModal] = useState(false)
const [currentTheme, setCurrentTheme] = useState('calm')

// ChatInterface.tsx
const [messages, setMessages] = useState<Message[]>([])
const [inputMessage, setInputMessage] = useState('')
const [isTyping, setIsTyping] = useState(false)
const [ws, setWs] = useState<WebSocket | null>(null)
const [currentAssistantMessage, setCurrentAssistantMessage] = useState('')
```

### Backend State (Python)

```python
# In-memory dictionaries
conversations_db = {}  # {conversation_id: Conversation}
active_sessions = {}   # {websocket_id: {conversation_id}}
```

## Data Models

### TypeScript Types (Frontend)

```typescript
interface Message {
  role: 'user' | 'assistant'
  content: string
  timestamp: string
}

interface Conversation {
  id: string
  title: string
  custom_context: string
  created_at: string
  updated_at: string
  messages: Message[]
  current_theme: string
}

interface ConversationSummary {
  id: string
  title: string
  created_at: string
  updated_at: string
  message_count: number
}

interface Theme {
  id: string
  name: string
  primaryColor: string
  secondaryColor: string
  backgroundColor: string
  // ... more color properties
}

interface WebSocketMessage {
  type: 'start' | 'chunk' | 'end' | 'error'
  content?: string
  theme?: string
  message?: string
}
```

### Python Models (Backend)

```python
from pydantic import BaseModel

class ConversationCreate(BaseModel):
    title: str
    custom_context: Optional[str] = ""

class ConversationUpdate(BaseModel):
    title: Optional[str] = None
    custom_context: Optional[str] = None
```

## Technology Stack Deep Dive

### Frontend Stack
```
React 18
  â”œâ”€â”€ TypeScript (type safety)
  â”œâ”€â”€ Vite (build tool, HMR)
  â”œâ”€â”€ CSS3 (animations, gradients)
  â””â”€â”€ WebSocket API (real-time)
```

### Backend Stack
```
FastAPI
  â”œâ”€â”€ Uvicorn (ASGI server)
  â”œâ”€â”€ httpx (async HTTP client)
  â”œâ”€â”€ WebSockets (bi-directional)
  â””â”€â”€ Python asyncio (async/await)
```

### AI Stack
```
Ollama
  â”œâ”€â”€ llama3.2 (default model)
  â”œâ”€â”€ Local inference
  â””â”€â”€ Streaming responses
```

## Security Considerations

### Current Implementation
- âœ… File size limits (1MB)
- âœ… File type validation (.txt, .md, .json)
- âœ… CORS configuration
- âœ… Input validation via Pydantic

### Production Recommendations
- ğŸ”’ Add user authentication (JWT)
- ğŸ”’ Implement rate limiting
- ğŸ”’ Use HTTPS/WSS
- ğŸ”’ Add database with proper isolation
- ğŸ”’ Sanitize user inputs
- ğŸ”’ Add API keys for backend
- ğŸ”’ Implement session management

## Scalability Path

### Current Limitations
- In-memory storage (lost on restart)
- Single server instance
- No user accounts
- No persistence

### Scaling Steps

**Phase 1: Persistence**
```
In-Memory â†’ SQLite â†’ PostgreSQL
```

**Phase 2: Multi-User**
```
Add authentication â†’ User isolation â†’ Session management
```

**Phase 3: Horizontal Scaling**
```
Add Redis â†’ Load balancer â†’ Multiple backend instances
```

**Phase 4: Advanced Features**
```
Add message queue â†’ Background jobs â†’ Analytics
```

## Development Workflow

```
1. Frontend Development
   â””â”€â”€ npm run dev (hot reload)
       â””â”€â”€ Edit .tsx/.css files
           â””â”€â”€ Changes reflect instantly

2. Backend Development
   â””â”€â”€ uvicorn --reload
       â””â”€â”€ Edit server_new.py
           â””â”€â”€ Server restarts automatically

3. Theme Development
   â””â”€â”€ Edit themes.ts
       â””â”€â”€ Add new theme
           â””â”€â”€ Update THEME_DETECTOR_PROMPT
               â””â”€â”€ Test with conversations
```

## Performance Optimization

### Frontend
- Component memoization (React.memo)
- Lazy loading for routes
- Debounced input handling
- Virtual scrolling for long message lists

### Backend
- Async/await throughout
- Connection pooling
- Message history truncation (20 messages)
- Streaming responses (low latency)

### Ollama
- Model kept in memory
- GPU acceleration (if available)
- Batch processing for theme detection

---

**Architecture designed for**: Simplicity, Extensibility, Real-time Performance
